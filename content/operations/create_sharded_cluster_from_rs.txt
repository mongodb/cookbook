---
title: How to expand a three member replica set into a sharded cluster composed of two three-member replica sets
created_at: 2011-11-30
recipe: true
author: Marc Bastien
---

### Outline

In this example, we will start with a single replica set containing three nodes and expand it into a sharded cluster composed of two three-member replica sets.  This example takes place in a test environment on localhost.  Just about all of the steps will be the same for a production environment, except where otherwise noted.  If you are following this example in a production environment, or a test set-up with multiple servers, simply replace "localhost" with the machine DNS name or IP address where applicable.  

Here is the order of operations:

0) Set up the three member replica set (if one does not exist already) and create a dummy collection
1) Start the config servers and create a cluster with one shard
2) Create a second replica set with three new mongod processess
3) Add the second replica set to the sharded cluster
4) Enable sharding on the desired collection(s)

### 0) Set up a three member replica set and create some dummy data

#### 0.1) Create the necessary directories.  In this example, the directories are /data/example/node1, /data/example/node2, and /data/example/node3

#### 0.2) Start three instances of mongod in three terminal windows

<% code 'javascript' do %>
$ bin/mongod --dbpath /data/example/node1 --port 10001 --replSet myset --oplogSize 700 --rest
<% end %>

<% code 'javascript' do %>
$ bin/mongod --dbpath /data/example/node2 --port 10002 --replSet myset --oplogSize 700 --rest
<% end %>

<% code 'javascript' do %>
$ bin/mongod --dbpath /data/example/node3 --port 10003 --replSet myset --oplogSize 700 --rest
<% end %>

NOTE: For the purpose of testing, the --oplogSize 700 option has been used to limit the oplog of each mongod process to 700MB instead of allowing each process to reserve 5% of the free disk space on the volume.  This should also allow each process to start up a little faster.  This should not be used in a production environment.  

#### 0.3) In a new terminal window, connect to one of the servers

<% code 'javascript' do %>
$ bin/mongo localhost:10001/admin
MongoDB shell version: 2.0.2-rc1
connecting to: localhost:10001/admin
> 
<% end %>

#### 0.4) Initialize the set

<% code 'javascript' do %>
> db.runCommand({"replSetInitiate" : {"_id" : "myset", "members" : [{"_id" : 1, "host" : "localhost:10001"}, {"_id" : 2, "host" : "localhost:10002"}, {"_id" : 3, "host" : "localhost:10003"}]}})
{
	"info" : "Config now saved locally.  Should come online in about a minute.",
	"ok" : 1
}
<% end %>

#### 0.5) Create a collection with some dummy data in it:

This little JavaScript program will write one million documents to the collection "test_collection" of the form:
<% code 'javascript' do %>
{ "_id" : ObjectId("4ed5420b8fc1dd1df5886f70"), "name" : "Greg", "user_id" : 4, "boolean" : true, "added_at" : ISODate("2011-11-29T20:35:23.121Z"), "number" : 74 }
<% end %>

<% code 'javascript' do %>
PRIMARY> use test
switched to db test
PRIMARY> people = ["Marc", "Bill", "George", "Eliot", "Matt", "Trey", "Tracy", "Greg", "Steve", "Kristina", "Katie", "Jeff"];
PRIMARY> for(var i=0; i<1000000; i++){
     name = people[Math.floor(Math.random()*people.length)];
     user_id = i;
     boolean = [true, false][Math.floor(Math.random()*2)];
     added_at = new Date();
     number = Math.floor(Math.random()*10001);
     db.test_collection.save({"name":name, "user_id":user_id, "boolean": boolean, "added_at":added_at, "number":number });
}
<% end %>

NOTE: Writing one million documents in the JS shell will take several minutes.

### 1) Start the config servers and create a cluster with one shard

NOTE: In a test environment, one config server will suffice.  In a production environment, the recommended set-up is to use three config servers.  This example will use three config servers.  

#### 1.1) Create the config directories: /data/example/config1, /data/example/config2, and /data/example/config3

#### 1.2) Start the config servers, each in a new terminal window

<% code 'javascript' do %>
$ bin/mongod --configsvr --dbpath /data/example/config1 --port 20001
<% end %>

<% code 'javascript' do %>
$ bin/mongod --configsvr --dbpath /data/example/config2 --port 20002
<% end %>

<% code 'javascript' do %>
$ bin/mongod --configsvr --dbpath /data/example/config3 --port 20003
<% end %>

#### 1.3) Start mongos in a new terminal 

<% code 'javascript' do %>
$ bin/mongos --configdb localhost:20001,localhost:20002,localhost:20003 --port 27017 --chunkSize 1
<% end %>

NOTE:  If you are using the dummy collection from step 0 and are just experimenting with sharding, you can use a small --chunkSize (1MB works well).  This way it will not be necessary to insert 64MB worth of documents before the Balancer starts to move them around.  This should not be used for production. 

Additionally, localhost:20000 is the address and host port of the config server, not the mongos process.  In the above example, mongos will be running on port 27017.  27017 is the default port for mongo, so --port 27017 may be omitted.  It has been included here only as an example.  

#### 1.4) In a new terminal, connect to the mongos process and add the first shard:

<% code 'javascript' do %>
$ bin/mongo localhost:27017/admin
MongoDB shell version: 2.0.2-rc1
connecting to: localhost:27017/admin
mongos> db.runCommand( { addshard : "myset/localhost:10001,localhost:10002,localhost:10003" } )
{ "shardAdded" : "myset", "ok" : 1 }
mongos> 
<% end %>

### 2) Create a second replica set with three new mongod processes

#### 2.1) Create the necessary directories.  In this example, the directories are /data/example/node4, /data/example/node5, and /data/example/node6

#### 2.2) Start three instances of mongod in three new terminal windows

<% code 'javascript' do %>
$ bin/mongod --dbpath /data/example/node4 --port 10004 --replSet myset2 --oplogSize 700 --rest
<% end %>

<% code 'javascript' do %>
$ bin/mongod --dbpath /data/example/node5 --port 10005 --replSet myset2 --oplogSize 700 --rest
<% end %>

<% code 'javascript' do %>
$ bin/mongod --dbpath /data/example/node6 --port 10006 --replSet myset2 --oplogSize 700 --rest
<% end %>

NOTE: As in step 0.2, the --oplogSize 700 option has been used.  This should not be used in a production environment. 

#### 2.3) In a new terminal window, connect to one of the servers

<% code 'javascript' do %>
$ bin/mongo localhost:10004/admin
MongoDB shell version: 2.0.2-rc1
connecting to: localhost:10004/admin
> 
<% end %>

#### 2.4) Initialize the set

<% code 'javascript' do %>
> db.runCommand({"replSetInitiate" : {"_id" : "myset2", "members" : [{"_id" : 1, "host" : "localhost:10004"}, {"_id" : 2, "host" : "localhost:10005"}, {"_id" : 3, "host" : "localhost:10006"}]}})
{
	"info" : "Config now saved locally.  Should come online in about a minute.",
	"ok" : 1
}
<% end %>

### 3) Add the second replica set to the sharded cluster

In the mongos terminal window:
<% code 'javascript' do %>
mongos> use admin
switched to db admin
mongos> db.runCommand( { addshard : "myset2/localhost:10004,localhost:10005,localhost:10006" } )
{ "shardAdded" : "myset2", "ok" : 1 }
<% end %>

You can verify that the two shards are set up properly by running the listshards command:
<% code 'javascript' do %>
mongos> db.runCommand({listshards:1})
{
	"shards" : [
		{
			"_id" : "myset",
			"host" : "myset/localhost:10001,localhost:10003,localhost:10002"
		},
		{
			"_id" : "myset2",
			"host" : "myset2/localhost:10004,localhost:10006,localhost:10005"
		}
	],
	"ok" : 1
}
<% end %>

### 4) Enable sharding on the collection(s) in question.  

#### 4.1) Enabling sharding on the database

<% code 'javascript' do %>
mongos> db.runCommand( { enablesharding : "test" } )
{ "ok" : 1 }
<% end %>

#### 4.2) Create an index on the desired shard key, if it does not already exist.  In this example, we will shard on the "number" key in the dummy collection.  

<% code 'javascript' do %>
mongos> use test
switched to db test
mongos> db.test_collection.ensureIndex({number:1})
<% end %>

#### 4.3) Shard the desired collection(s)

<% code 'javascript' do %>
mongos> use admin
switched to db admin
mongos> db.runCommand( { shardcollection : "test.test_collection", key : {"number":1} })
{ "collectionsharded" : "test.test_collection", "ok" : 1 }
mongos> 
<% end %>

The collection "test_collection" is now sharded!  In a few minutes the Balancer will begin to redistribute the chunks.  You can confirm this by switching to the test database and running db.stats() or db.printShardingStatus().  You can also confirm that the chunks been redistributed by looking in the data directories.  If the sharded collection is written to again, the documents will be distributed between the new shards.  

<% code 'javascript' do %>
mongos> use test
switched to db test
mongos> db.stats()
{
	"raw" : {
		"myset/localhost:10001,localhost:10003,localhost:10002" : {
			"db" : "test",
			"collections" : 3,
			"objects" : 973887,
			"avgObjSize" : 100.33173458522396,
			"dataSize" : 97711772,
			"storageSize" : 141258752,
			"numExtents" : 15,
			"indexes" : 2,
			"indexSize" : 56978544,
			"fileSize" : 1006632960,
			"nsSizeMB" : 16,
			"ok" : 1
		},
		"myset2/localhost:10004,localhost:10006,localhost:10005" : {
			"db" : "test",
			"collections" : 3,
			"objects" : 26125,
			"avgObjSize" : 100.33286124401914,
			"dataSize" : 2621196,
			"storageSize" : 11194368,
			"numExtents" : 8,
			"indexes" : 2,
			"indexSize" : 2093056,
			"fileSize" : 201326592,
			"nsSizeMB" : 16,
			"ok" : 1
		}
	},
	"objects" : 1000012,
	"avgObjSize" : 100.33176401883178,
	"dataSize" : 100332968,
	"storageSize" : 152453120,
	"numExtents" : 23,
	"indexes" : 4,
	"indexSize" : 59071600,
	"fileSize" : 1207959552,
	"ok" : 1
}
mongos> db.printShardingStatus()
--- Sharding Status --- 
  sharding version: { "_id" : 1, "version" : 3 }
  shards:
	{  "_id" : "myset",  "host" : "myset/localhost:10001,localhost:10003,localhost:10002" }
	{  "_id" : "myset2",  "host" : "myset2/localhost:10004,localhost:10006,localhost:10005" }
  databases:
	{  "_id" : "admin",  "partitioned" : false,  "primary" : "config" }
	{  "_id" : "test",  "partitioned" : true,  "primary" : "myset" }
		test.test_collection chunks:
				myset2	5
				myset	186
			too many chunks to print, use verbose if you want to force print

mongos> db.stats()
{
	"raw" : {
		"myset/localhost:10001,localhost:10003,localhost:10002" : {
			"db" : "test",
			"collections" : 3,
			"objects" : 910960,
			"avgObjSize" : 100.33197066830596,
			"dataSize" : 91398412,
			"storageSize" : 141258752,
			"numExtents" : 15,
			"indexes" : 2,
			"indexSize" : 55400576,
			"fileSize" : 1006632960,
			"nsSizeMB" : 16,
			"ok" : 1
		},
		"myset2/localhost:10004,localhost:10006,localhost:10005" : {
			"db" : "test",
			"collections" : 3,
			"objects" : 89052,
			"avgObjSize" : 100.32942550419979,
			"dataSize" : 8934536,
			"storageSize" : 11194368,
			"numExtents" : 8,
			"indexes" : 2,
			"indexSize" : 7178528,
			"fileSize" : 201326592,
			"nsSizeMB" : 16,
			"ok" : 1
		}
	},
	"objects" : 1000012,
	"avgObjSize" : 100.33174401907178,
	"dataSize" : 100332948,
	"storageSize" : 152453120,
	"numExtents" : 23,
	"indexes" : 4,
	"indexSize" : 62579104,
	"fileSize" : 1207959552,
	"ok" : 1
}
mongos> db.printShardingStatus()
--- Sharding Status --- 
  sharding version: { "_id" : 1, "version" : 3 }
  shards:
	{  "_id" : "myset",  "host" : "myset/localhost:10001,localhost:10003,localhost:10002" }
	{  "_id" : "myset2",  "host" : "myset2/localhost:10004,localhost:10006,localhost:10005" }
  databases:
	{  "_id" : "admin",  "partitioned" : false,  "primary" : "config" }
	{  "_id" : "test",  "partitioned" : true,  "primary" : "myset" }
		test.test_collection chunks:
				myset2	17
				myset	174
			too many chunks to print, use verbose if you want to force print

mongos> 
<% end %>

As time passes, more chunks are migrated to the shard on replica set "myset2".  